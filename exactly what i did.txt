WHAT WE DID (IN SHORT)
We evaluated an offline speech-to-text system using pre-trained Whisper models.

Specifically, we:

Took a clean speech audio from the LibriSpeech dataset

Transcribed it offline using Whisper

Measured accuracy using Word Error Rate (WER)

Compared different Whisper model sizes (tiny, base, small)

Tested robustness by adding noise

Simulated streaming transcription using audio chunking

Analyzed accuracy vs speed trade-offs

ğŸ‘‰ No model was trained. Only evaluated.

ğŸ”¹ WHAT IS THE FINAL RESULT?
Whisper works offline

Achieved low WER (~3.57%) on clean speech

Larger models â†’ better accuracy but slower

Noise increases WER but transcription remains usable

Chunk-based transcription slightly reduces accuracy for longer audio

ğŸ”¹ HOW TO DO THE ENTIRE PROJECT AGAIN (STEP-BY-STEP, SHORT)
1ï¸âƒ£ Setup
Install Python, FFmpeg, Whisper, JiWER

Create project folders: data/, scripts/, results/, plots/

2ï¸âƒ£ Dataset
Download LibriSpeech â†’ test-clean

Pick one .flac file

Convert to .wav using FFmpeg

Copy transcript into ground_truth.txt

3ï¸âƒ£ Baseline Transcription
Run Whisper (base.en) on clean audio

Save output text

Record inference time

4ï¸âƒ£ Accuracy Evaluation
Normalize text (lowercase, remove punctuation)

Compute WER

This is the main metric

5ï¸âƒ£ Model Comparison
Run tiny.en, base.en, small.en

Measure time + WER

Save results in CSV

6ï¸âƒ£ Noise Robustness
Add white noise to audio

Transcribe noisy audio

Compute WER again

Compare with clean audio

7ï¸âƒ£ Chunk-Based Transcription
Split audio into fixed-length chunks

Transcribe each chunk

Merge text

Compute WER

8ï¸âƒ£ Visualization & Report
Plot Model vs WER

Summarize results in README

ğŸ”¹ ONE-LINE PROJECT DESCRIPTION (MEMORIZE)
â€œThis project evaluates the accuracy, robustness, and efficiency of an offline speech-to-text system using pre-trained Whisper models.â€

ğŸ”¹ IF ASKED â€œDID YOU TRAIN THE MODEL?â€
No. Whisper models are pre-trained. We evaluated different model sizes on benchmark speech data.

ğŸ”¹ WHY THIS PROJECT IS GOOD
âœ” Real-world AI
âœ” Correct methodology
âœ” Quantitative results
âœ” Reproducible
âœ” Resume & viva ready